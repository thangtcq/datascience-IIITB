{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Liquor Sales Data Analysis"
      ],
      "metadata": {
        "id": "lsb7KcSTAuna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective\n",
        "\n",
        "In this case study, you will learn the principles of hands-on data processing and analysis using\n",
        "a detailed dataset on liquor sales spanning 2020 to 2025. This assignment aims to give you\n",
        "practical experience in processing large datasets using tech stacks such as AWS RDS, HBase,\n",
        "and Hadoop MapReduce. You will not only apply the techniques covered in the project modules,\n",
        "but also gain insights into the complexities of business data analytics. At the end of this\n",
        "assignment, you will have developed a robust understanding of the following:\n",
        "• Data ingestion processes using cloud-based tools like AWS RDS and HBase.\n",
        "• Data cleaning and preparation to ensure high-quality analysis.\n",
        "• Applying MapReduce to solve real-world analytics problems.\n",
        "• Creating actionable insights and recommendations based on the analysis.\n",
        "This hands-on approach will bridge the gap between theoretical learning and practical implementation,\n",
        "preparing you for real-world challenges in the field of data analytics.\n",
        "\n"
      ],
      "metadata": {
        "id": "DGQVIB4mEFrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Business Objective:\n",
        "The liquor industry is a significant contributor to the retail economy, particularly in regions where\n",
        "sales are highly regulated and tracked. For liquor businesses, understanding sales trends is vital to\n",
        "maintaining competitive advantage, meeting customer demand, and ensuring efficient operations.\n",
        "As an analyst, you are tasked with analyzing detailed liquor sales data from 2020 to 2025 to uncover\n",
        "patterns and insights that can drive strategic decision-making. The objective is to identify trends in\n",
        "consumer preferences, regional sales performance, and product popularity, enabling stakeholders to\n",
        "optimize inventory management, boost profitability, and enhance customer satisfaction."
      ],
      "metadata": {
        "id": "q6Dutz323wAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hadoop and MapReduce Assignment Tasks:\n",
        "\n",
        "<br> Data Cleaning Tasks: </br>\n",
        "<br>Task 1:  Data Cleaning</br>\n",
        "\n",
        "<br> Data Ingestion Tasks: </br>\n",
        "<br>Task 2: Upload Liquor Sales Data to AWS RDS</br>\n",
        "<br>Task 3: Ingest Data into HBase</br>\n",
        "\n",
        "\n",
        "<r>Data Analysis Using MapReduce:</br>\n",
        "<br>Task 4: Total Revenue by Store</br>\n",
        "<br>Task 5: Top-Selling Liquor Categories</br>\n",
        "<br>Task 6: County-Level Sales Analysis</br>\n",
        "<br>Task 7: Store Performance Analysis</br>\n",
        "<br>Task 8: Trends in Liquor Sales Over Time</br>\n",
        "<br>Task 9: Vendor Performance</br>\n",
        "\n",
        "\n",
        "**NOTE:** The marks given along with headings and sub-headings are cumulative marks for those particular headings/sub-headings.<br>\n",
        "\n",
        "The actual marks for each task are specified within the tasks themselves.\n",
        "\n",
        "For example, marks given with heading *2* or sub-heading *2.1* are the cumulative marks, for your reference only. <br>\n",
        "\n",
        "The marks you will receive for completing tasks are given with the tasks.\n",
        "\n",
        "Suppose the marks for two tasks are: 3 marks for 2.1.1 and 2 marks for 3.2.2, or\n",
        "* 2.1.1 [3 marks]\n",
        "* 3.2.2 [2 marks]\n",
        "\n",
        "then, you will earn 3 marks for completing task 2.1.1 and 2 marks for completing task 3.2.2."
      ],
      "metadata": {
        "id": "-OVfUMlHFkZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "YdQjht7dUiHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Understanding\n",
        "The dataset link can be accessed from the following [link](https://liquor-data.s3.us-east-1.amazonaws.com/Liquor_Sales.csv).\n",
        "The dataset contains liquor sales data from multiple stores across various states, providing rich information for analysis. The fields are as follows:\n"
      ],
      "metadata": {
        "id": "0eaCZjHIvfuI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Variable              | Class            | Description                                                     |\n",
        "|-----------------------|------------------|-----------------------------------------------------------------|\n",
        "| Invoice/Item Number   | String/Integer   | Unique identifier for each sale.                                |\n",
        "| Date                  | Date             | The date of the sale.                                           |\n",
        "| Store Number          | Integer          | Unique identifier for the store.                                |\n",
        "| Store Name            | String           | Name of the store.                                              |\n",
        "| Address               | String           | Store address.                                                  |\n",
        "| City                  | String           | City where the store is located.                                |\n",
        "| Zip Code              | String/Integer   | ZIP code of the store location.                                 |\n",
        "| Store Location        | String/GeoPoint  | GPS coordinates of the store.                                   |\n",
        "| County Number         | Integer          | Unique identifier for the county.                               |\n",
        "| County                | String           | Name of the county.                                             |\n",
        "| Category              | Integer          | Liquor category code.                                           |\n",
        "| Category Name         | String           | Name of the liquor category (e.g., Whiskey, Vodka).             |\n",
        "| Vendor Number         | Integer          | Vendor's unique identifier.                                     |\n",
        "| Vendor Name           | String           | Name of the vendor/distributor.                                 |\n",
        "| Item Number           | Integer          | Product's unique identifier.                                    |\n",
        "| Item Description      | String           | Description of the liquor product.                              |\n",
        "| Pack                  | Integer          | Number of bottles in a pack.                                    |\n",
        "| Bottle Volume (ml)    | Float/Integer    | Volume of a single bottle in milliliters.                       |\n",
        "| State Bottle Cost     | Float            | Cost per bottle for the state.                                  |\n",
        "| State Bottle Retail   | Float            | Retail price per bottle.                                        |\n",
        "| Bottles Sold          | Integer          | Number of bottles sold.                                         |\n",
        "| Sale (Dollars)        | Float            | Total revenue from the sale.                                    |\n",
        "| Volume Sold (Liters)  | Float            | Volume sold in liters.                                          |\n",
        "| Volume Sold (Gallons) | Float            | Volume sold in gallons.                                         |\n"
      ],
      "metadata": {
        "id": "LI6qC5IDxZU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries and Load Dataset"
      ],
      "metadata": {
        "id": "nM2X-s6lycvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mrjob==0.7.4"
      ],
      "metadata": {
        "id": "OQjeiFgWE6SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libraries you will be using for analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mrjob.job import MRJob\n",
        "import csv\n",
        "from sqlalchemy import create_engine\n",
        "import subprocess\n",
        "import zipfile\n",
        "import os\n",
        "import requests"
      ],
      "metadata": {
        "id": "9ggMELWEE7X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the URL and file paths\n",
        "url = 'https://kh3-ls-storage.s3.us-east-1.amazonaws.com/UPGrad/Liquor_Sales.zip'\n",
        "zip_file_path = '/mnt/data/Liquor_Sales.zip'\n",
        "extracted_folder_path = '/mnt/data/'\n",
        "excel_file_name = 'Liquor_Sales.xlsx'\n",
        "#cleaned_file_path = '/mnt/data/cleaned_liquor_sales.xlsx'\n",
        "\n",
        "# Download the ZIP file\n",
        "response = requests.get(url)\n",
        "with open(zip_file_path, 'wb') as file:\n",
        "    file.write(response.content)\n",
        "print(\"ZIP file downloaded successfully.\")\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "print(\"ZIP file extracted successfully.\")\n",
        "\n",
        "# Load the data from the extracted Excel file\n",
        "excel_file_path = os.path.join(extracted_folder_path, excel_file_name)\n",
        "data = pd.read_excel(excel_file_path, sheet_name='Sheet1')"
      ],
      "metadata": {
        "id": "vSmAMy8xHWqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1** Data Cleaning\n",
        "<font color = red>[5 marks]</font> <br>"
      ],
      "metadata": {
        "id": "klWHD3amIOgn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1** Fixing Columns"
      ],
      "metadata": {
        "id": "B1LHJP0IIV2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns = [col.strip().replace(' ', '_').replace('/', '_') for col in data.columns]\n",
        "\n",
        "# Display the updated column names\n",
        "print(\"Updated Column Names:\")\n",
        "print(data.columns)\n",
        "\n",
        "# Ensure correct data types based on the data dictionary\n",
        "data['Invoice_Item_Number'] = data['Invoice_Item_Number'].astype(str)\n",
        "data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
        "data['Store_Number'] = data['Store_Number'].astype(int)\n",
        "data['Store_Name'] = data['Store_Name'].astype(str)\n",
        "data['Address'] = data['Address'].astype(str)\n",
        "data['City'] = data['City'].astype(str)\n",
        "data['Zip_Code'] = data['Zip_Code'].astype(str)\n",
        "data['Store_Location'] = data['Store_Location'].astype(str)\n",
        "data['County_Number'] = data['County_Number'].astype(int)\n",
        "data['County'] = data['County'].astype(str)\n",
        "data['Category'] = data['Category'].astype(int)\n",
        "data['Category_Name'] = data['Category_Name'].astype(str)\n",
        "data['Vendor_Number'] = data['Vendor_Number'].astype(int)\n",
        "data['Vendor_Name'] = data['Vendor_Name'].astype(str)\n",
        "data['Item_Number'] = data['Item_Number'].astype(int)\n",
        "data['Item_Description'] = data['Item_Description'].astype(str)\n",
        "data['Pack'] = data['Pack'].astype(int)\n",
        "data['Bottle_Volume_(ml)'] = data['Bottle_Volume_(ml)'].astype(float)\n",
        "data['State_Bottle_Cost'] = data['State_Bottle_Cost'].astype(float)\n",
        "data['State_Bottle_Retail'] = data['State_Bottle_Retail'].astype(float)\n",
        "data['Bottles_Sold'] = data['Bottles_Sold'].astype(int)\n",
        "data['Sale_(Dollars)'] = data['Sale_(Dollars)'].astype(float)\n",
        "data['Volume_Sold_(Liters)'] = data['Volume_Sold_(Liters)'].astype(float)\n",
        "data['Volume_Sold_(Gallons)'] = data['Volume_Sold_(Gallons)'].astype(float)\n",
        "\n",
        "# Remove rows with invalid dates\n",
        "data.dropna(subset=['Date'], inplace=True)\n",
        "\n",
        "# Standardize categorical columns\n",
        "data['City'] = data['City'].str.title()\n",
        "data['County'] = data['County'].str.title()\n",
        "data['Store_Name'] = data['Store_Name'].str.title()\n",
        "data['Category_Name'] = data['Category_Name'].str.title()\n",
        "data['Vendor_Name'] = data['Vendor_Name'].str.title()"
      ],
      "metadata": {
        "id": "nuJGwWNJHa1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2** Fixing Rows"
      ],
      "metadata": {
        "id": "zVHc70NxIZHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate records\n",
        "initial_duplicate_count = data.shape[0]\n",
        "data.drop_duplicates(inplace=True)\n",
        "final_duplicate_count = data.shape[0]\n",
        "\n",
        "print(f\"Rows before removing duplicates: {initial_duplicate_count}\")\n",
        "print(f\"Rows after removing duplicates: {final_duplicate_count}\")"
      ],
      "metadata": {
        "id": "Acvtcs8vKgDx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "64aad2ab-2673-43f7-d2f2-5176d53ebfcb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2292454487.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.3** Handling Missing Values"
      ],
      "metadata": {
        "id": "FpKVPq6TIbkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for any remaining missing values\n",
        "# Remove rows with missing or incomplete values\n",
        "initial_row_count = data.shape[0]\n",
        "data.dropna(inplace=True)\n",
        "final_row_count = data.shape[0]\n",
        "\n",
        "print(f\"Rows before removing missing values: {initial_row_count}\")\n",
        "print(f\"Rows after removing missing values: {final_row_count}\")\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing Values After Initial Cleaning:\")\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "0-VffKlAKgap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "371b8086-9945-4ba1-e551-75f788a1f3d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1312135769.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Remove rows with missing or incomplete values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minitial_row_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfinal_row_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.4** Handling Outliers"
      ],
      "metadata": {
        "id": "v10ZAouYIgKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numerical columns\n",
        "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Apply IQR method to each numerical column\n",
        "for col in numerical_columns:\n",
        "    Q1 = data[col].quantile(0.25)\n",
        "    Q3 = data[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    initial_outlier_count = data.shape[0]\n",
        "    data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n",
        "    final_outlier_count = data.shape[0]\n",
        "    print(f\"Column: {col}\")\n",
        "    print(f\"Rows before removing outliers: {initial_outlier_count}\")\n",
        "    print(f\"Rows after removing outliers: {final_outlier_count}\")"
      ],
      "metadata": {
        "id": "jzxgUXgeKg3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2** Data Ingestion Tasks\n",
        "<font color = red>[15 marks]</font> <br>"
      ],
      "metadata": {
        "id": "9uZWYMvVIsJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Upload Liquor Sales Data to AWS RDS\n",
        "<font color = red>[5 marks]</font> <br>"
      ],
      "metadata": {
        "id": "Ziegg_DCI31b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AWS RDS connection details\n",
        "rds_host = 'your_rds_host'\n",
        "rds_port = 'your_rds_port'\n",
        "rds_dbname = 'your_rds_dbname'\n",
        "rds_user = 'your_rds_user'\n",
        "rds_password = 'your_rds_password'\n",
        "\n",
        "# Create a connection to AWS RDS\n",
        "engine = create_engine(f'mysql+pymysql://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{rds_dbname}')\n",
        "\n",
        "# Upload data to AWS RDS\n",
        "data.to_sql('liquor_sales', con=engine, if_exists='replace', index=False)\n",
        "print(\"Data uploaded to AWS RDS successfully.\")"
      ],
      "metadata": {
        "id": "Ajsnm_-bKh-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.2 Ingest Data to HBase\n",
        "<font color = red>[10 marks]</font> <br>"
      ],
      "metadata": {
        "id": "DAC2ze1AI4cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define HBase schema\n",
        "hbase_table = 'liquor_sales'\n",
        "column_family = 'cf'\n",
        "\n",
        "# Use Apache Sqoop to transfer data from AWS RDS to HBase\n",
        "sqoop_command = f\"\"\"\n",
        "sqoop import \\\n",
        "--connect jdbc:mysql://{rds_host}:{rds_port}/{rds_dbname} \\\n",
        "--username {rds_user} \\\n",
        "--password {rds_password} \\\n",
        "--table liquor_sales \\\n",
        "--hbase-table {hbase_table} \\\n",
        "--column-family {column_family} \\\n",
        "--hbase-row-key Invoice_Item_Number\n",
        "\"\"\"\n",
        "\n",
        "# Execute the Sqoop command\n",
        "subprocess.run(sqoop_command, shell=True, check=True)\n",
        "print(\"Data ingested to HBase successfully.\")"
      ],
      "metadata": {
        "id": "56hMxxP3KieY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3** Analytics Queries using MapReduce\n",
        "<font color = red>[60 marks]</font> <br>"
      ],
      "metadata": {
        "id": "bVIgu2q3I7vR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 Total Revenue by Store\n",
        "<font color = red>[10 marks]</font> <br>"
      ],
      "metadata": {
        "id": "0v-UC9gWI_fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MRTotalRevenueByStore(MRJob):\n",
        "\n",
        "    # This is the Mapper\n",
        "    def mapper(self, _, line):\n",
        "      fields = line.split(',')\n",
        "      store_name = fields[3]\n",
        "      sale_dollars = float(fields[21])\n",
        "      yield store_name, sale_dollars\n",
        "\n",
        "    # This is the Reducer\n",
        "    def reducer(self, store_name, sales):\n",
        "      yield store_name, sum(sales)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRTotalRevenueByStore.run()"
      ],
      "metadata": {
        "id": "JBdUsNFKKi9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 Top-Selling Categories\n",
        "<font color = red>[10 marks]</font> <br>"
      ],
      "metadata": {
        "id": "bFZB3OjtJArF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MRTopSellingLiquorCategories(MRJob):\n",
        "\n",
        "    # This is the Mapper\n",
        "    def mapper(self, _, line):\n",
        "      fields = line.split(',')\n",
        "      category_name = fields[11]\n",
        "      bottles_sold = int(fields[20])\n",
        "      sale_dollars = float(fields[21])\n",
        "      yield category_name, (bottles_sold, sale_dollars)\n",
        "\n",
        "    # This is the Reducer\n",
        "    def reducer(self, category_name, values):\n",
        "      total_bottles_sold = 0\n",
        "      total_sales = 0\n",
        "      for bottles_sold, sale_dollars in values:\n",
        "          total_bottles_sold += bottles_sold\n",
        "          total_sales += sale_dollars\n",
        "      yield category_name, (total_bottles_sold, total_sales)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRTopSellingLiquorCategories.run()"
      ],
      "metadata": {
        "id": "N37STBpbKjso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3 County-Level Sales Analysis\n",
        "<font color = red>[10 marks]</font> <br>"
      ],
      "metadata": {
        "id": "HU9i_JaZJByS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MRCountyLevelSalesAnalysis(MRJob):\n",
        "\n",
        "    # This is the Mapper\n",
        "    def mapper(self, _, line):\n",
        "      fields = line.split(',')\n",
        "      county = fields[9]\n",
        "      sale_dollars = float(fields[21])\n",
        "      volume_sold_liters = float(fields[22])\n",
        "      volume_sold_gallons = float(fields[23])\n",
        "      yield county, (sale_dollars, volume_sold_liters, volume_sold_gallons)\n",
        "\n",
        "    # This is the Reducer\n",
        "    def reducer(self, county, values):\n",
        "      total_sales = 0\n",
        "      total_volume_liters = 0\n",
        "      total_volume_gallons = 0\n",
        "      for sale_dollars, volume_sold_liters, volume_sold_gallons in values:\n",
        "          total_sales += sale_dollars\n",
        "          total_volume_liters += volume_sold_liters\n",
        "          total_volume_gallons += volume_sold_gallons\n",
        "      yield county, (total_sales, total_volume_liters, total_volume_gallons)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRCountyLevelSalesAnalysis.run()"
      ],
      "metadata": {
        "id": "D_PzFwc0KkPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.4 Store Performance Analysis\n",
        "<font color = red>[10 marks]</font> <br>"
      ],
      "metadata": {
        "id": "FyyYJe5QJC3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MRStorePerformanceAnalysis(MRJob):\n",
        "\n",
        "    # This is the Mapper\n",
        "    def mapper(self, _, line):\n",
        "      fields = line.split(',')\n",
        "      store_name = fields[3]\n",
        "      sale_dollars = float(fields[21])\n",
        "      volume_sold_liters = float(fields[22])\n",
        "      yield store_name, (sale_dollars, volume_sold_liters)\n",
        "\n",
        "    # This is the Reducer\n",
        "    def reducer(self, store_name, values):\n",
        "      total_sales = 0\n",
        "      total_volume = 0\n",
        "      count = 0\n",
        "      for sale_dollars, volume_sold_liters in values:\n",
        "          total_sales += sale_dollars\n",
        "          total_volume += volume_sold_liters\n",
        "          count += 1\n",
        "      avg_sales_per_transaction = total_sales / count\n",
        "      yield store_name, (total_sales, total_volume, avg_sales_per_transaction)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRStorePerformanceAnalysis.run()"
      ],
      "metadata": {
        "id": "z_4BireWKkpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.5 Trends in Liquor Sales Over Time\n",
        "<font color = red>[10 marks]</font> <br>"
      ],
      "metadata": {
        "id": "tCyeRMr-JD2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MRLiquorSalesTrends(MRJob):\n",
        "\n",
        "    # This is the Mapper\n",
        "    def mapper(self, _, line):\n",
        "      fields = line.split(',')\n",
        "      date = fields[1]\n",
        "      month = date[:7]  # Extract YYYY-MM\n",
        "      sale_dollars = float(fields[21])\n",
        "      volume_sold_liters = float(fields[22])\n",
        "      yield month, (sale_dollars, volume_sold_liters)\n",
        "\n",
        "    # This is the Reducer\n",
        "    def reducer(self, month, values):\n",
        "      total_sales = 0\n",
        "      total_volume = 0\n",
        "      for sale_dollars, volume_sold_liters in values:\n",
        "          total_sales += sale_dollars\n",
        "          total_volume += volume_sold_liters\n",
        "      yield month, (total_sales, total_volume)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRLiquorSalesTrends.run()"
      ],
      "metadata": {
        "id": "x4UpwN3xKlJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.6 Vendor Performance\n",
        "<font color = red>[10 marks]</font> <br>"
      ],
      "metadata": {
        "id": "fbwsgl0rJFHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MRVendorPerformance(MRJob):\n",
        "\n",
        "    # This is the Mapper\n",
        "    def mapper(self, _, line):\n",
        "      fields = line.split(',')\n",
        "      vendor_name = fields[13]\n",
        "      sale_dollars = float(fields[21])\n",
        "      volume_sold_liters = float(fields[22])\n",
        "      yield vendor_name, (sale_dollars, volume_sold_liters)\n",
        "\n",
        "    # This is the Reducer\n",
        "    def reducer(self, vendor_name, values):\n",
        "      total_sales = 0\n",
        "      total_volume = 0\n",
        "      for sale_dollars, volume_sold_liters in values:\n",
        "          total_sales += sale_dollars\n",
        "          total_volume += volume_sold_liters\n",
        "      yield vendor_name, (total_sales, total_volume)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRVendorPerformance.run()"
      ],
      "metadata": {
        "id": "tuPk-tPrIOWT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}